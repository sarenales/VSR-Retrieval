{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn+wEOTu+K8K06CFp0saS6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarenales/VSR-Retrieval/blob/main/Extraccion_resultados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFA"
      ],
      "metadata": {
        "id": "FPEz2pkkpxYW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBra8bVzpmy2"
      },
      "outputs": [],
      "source": [
        "!git clone --single-branch --branch feature/add_transformers https://github.com/OFA-Sys/OFA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OFA/transformers/"
      ],
      "metadata": {
        "id": "YrhFtdGDpzLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/OFA-Sys/OFA-large"
      ],
      "metadata": {
        "id": "8aXTikLfp0TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.ofa.generate import sequence_generator"
      ],
      "metadata": {
        "id": "396eMxolp12d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import OFATokenizer, OFAModel\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ofa_model = OFAModel.from_pretrained(\"./OFA-large\", torch_dtype=torch.bfloat16, use_cache=False).to(device)\n",
        "ofa_tokenizer = OFATokenizer.from_pretrained(\"./OFA-large\")"
      ],
      "metadata": {
        "id": "EBiYA85yp2vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "mean, std = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
        "resolution = 480 # LARGE --- 384  BASE\n",
        "\n",
        "def load_image(image):\n",
        "    patch_resize_transform = transforms.Compose([\n",
        "            transforms.Resize((resolution, resolution), interpolation=Image.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean, std=std)\n",
        "        ])\n",
        "    patch_img = patch_resize_transform(image).unsqueeze(0).to(device)\n",
        "    return patch_img"
      ],
      "metadata": {
        "id": "JnKmv1L4p3ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET"
      ],
      "metadata": {
        "id": "DkFyXjOxp4dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cambridgeltl/visual-spatial-reasoning.git"
      ],
      "metadata": {
        "id": "fcm3fvKup5we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "archivo_jsonl = \"/content/visual-spatial-reasoning/data/data_files/all_vsr_validated_data.jsonl\"\n",
        "train = []\n",
        "with open(archivo_jsonl, \"r\") as f:\n",
        "  for linea in f:\n",
        "    objeto = json.loads(linea)\n",
        "    train.append(objeto)"
      ],
      "metadata": {
        "id": "5CYS7G8Mp7Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diccionario_opuesto ={\n",
        "    # Adjacency (10)\n",
        "    \"adjacent to\":\"alongside\",\n",
        "    \"alongside\": \"Adjacent to\",\n",
        "    \"at the side of\":\"against\",\n",
        "    \"at the right side of\":\"at the left side of\",\n",
        "    \"at the left side of\": \"at the right side of\",\n",
        "    \"attached to\":\"against\",\n",
        "    \"at the back of\":\"ahead of\",\n",
        "    \"ahead of\":\"at the back of\",\n",
        "    \"against\": \"ahead of\",\n",
        "    \"at the edge of\":\"Adjacent to\",\n",
        "\n",
        "  # Directional (16)\n",
        "    \"off\":\"up\",\n",
        "    \"past\":\"across from\",\n",
        "    \"toward\":\"down\",\n",
        "    \"down\":\"up\",\n",
        "    \"deep down\":\"up\",\n",
        "    \"up\":\"deep down\",\n",
        "    \"away from\":\"across from\",\n",
        "    \"along\":\"Adjacent to\",\n",
        "    \"around\":\"off\",\n",
        "    \"from\":\"away from\",\n",
        "    \"into\":\"off\",\n",
        "    \"to\":\"in front of\",\n",
        "    \"across\":\"off\"  ,\n",
        "    \"across from\":\"Adjacent to\" ,\n",
        "    \"through\":\"Adjacent to\",\n",
        "    \"down from\":\"into\"    ,\n",
        "\n",
        "  # Orientation (4)\n",
        "    \"facing\":\"facing away from\"  ,\n",
        "    \"facing away from\":\"facing\"  ,\n",
        "    \"parallel to\":\"perpendicular to\"  ,\n",
        "    \"perpendicular to\":\"parallel to\"  ,\n",
        "\n",
        "  # Projective (12)\n",
        "    \"on top of\":\"beneath\"  ,\n",
        "    \"beneath\":\"on top of\"  ,\n",
        "    \"beside\":\"far from\"  ,\n",
        "    \"behind\":\"in front of\"  ,\n",
        "    \"left of\":\"right of\"  ,\n",
        "    \"right of\":\"left of\"  ,\n",
        "    \"under\":\"over\"  ,\n",
        "    \"in front of\":\"behind\"  ,\n",
        "    \"below\":\"above\"  ,\n",
        "    \"above\":\"below\"  ,\n",
        "    \"over\":\"under\"  ,\n",
        "    \"in the middle of\": \"above\",\n",
        "\n",
        "    # Proximity (6)\n",
        "    \"by\":\"far from\"  ,\n",
        "    \"close to\": \"far from\" ,\n",
        "    \"near\":\"far from\"  ,\n",
        "    \"far from\":\"close to\"  ,\n",
        "    \"far away from\":\"close to\"  ,\n",
        "\n",
        "    # Topological (18)\n",
        "    \"connected to\":\"detached from\"  ,\n",
        "    \"detached from\":\"part of\"  ,\n",
        "    \"has as a part\":\"detached from\"  ,\n",
        "    \"part of\":\"detached from\"  ,\n",
        "    \"contains\":\"detached from\"  ,\n",
        "    \"within\":\"out of\"  ,\n",
        "    \"at\":\"out of\"  ,\n",
        "    \"on\":\"out of\"  ,\n",
        "    \"in\":\"out of\"  ,\n",
        "    \"with\":\"out of\"  ,\n",
        "    \"surrounding\":\"out of\"  ,\n",
        "    \"among\":\"out of\"  ,\n",
        "    \"consists of\":\"out of\"  ,\n",
        "    \"out of\":\"between\"  ,\n",
        "    \"between\":\"out to\"  ,\n",
        "    \"inside\":\"outside\"  ,\n",
        "    \"outside\":\"inside\"  ,\n",
        "    \"touching\": \"detached from\"  ,\n",
        "\n",
        "    # Unallocated (6)\n",
        "    \"beyond\":\"enclosed by\"  ,\n",
        "    \"next to\":\"beyond\"  ,\n",
        "    \"opposite to\":\"Adjacent to\"  ,\n",
        "    \"after\":\"among\"  ,\n",
        "    #\"among\":\"after\"  ,\n",
        "    \"enclosed by\":\"beyond\"\n",
        "}"
      ],
      "metadata": {
        "id": "n0Q7-nZ_p8k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obtener_contrario(palabra, diccionario):\n",
        "  if palabra in diccionario:\n",
        "    return diccionario[palabra]\n",
        "  else:\n",
        "    return \"Palabra no encontrada\""
      ],
      "metadata": {
        "id": "8J1cR4v-p-Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def saber_split(url):\n",
        "  if 'train' in url:\n",
        "    return \"train\"\n",
        "  else:\n",
        "    return \"dev\""
      ],
      "metadata": {
        "id": "RBV6aVpNqAf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtro = {}\n",
        "cont = 0\n",
        "\n",
        "for elemento in train:\n",
        "  if elemento.get(\"label\") == 1:\n",
        "\n",
        "    nuevo_elemento = {\n",
        "        \"image\" : elemento.get(\"image\"),\n",
        "        \"image_link\": elemento.get(\"image_link\"),\n",
        "        \"caption+\" : elemento.get(\"caption\"),\n",
        "        \"caption-\" :  elemento.get(\"caption\").replace(elemento.get(\"relation\"),  obtener_contrario(elemento.get(\"relation\"), diccionario_opuesto)),\n",
        "        \"relation+\" : elemento.get(\"relation\"),\n",
        "        \"relation-\" : obtener_contrario(elemento.get(\"relation\"), diccionario_opuesto),\n",
        "        \"split\": saber_split(elemento.get(\"image_link\"))\n",
        "    }\n",
        "\n",
        "    filtro[cont] = nuevo_elemento\n",
        "    cont +=1\n",
        "\n",
        "with open(\"filtrado.json\", \"w\") as archivo:\n",
        "  json.dump(filtro, archivo)\n",
        "\n",
        "\n",
        "print(f\"Nuevo JSON creado exitosamente con los elementos filtrados. Número de elementos {cont}.\")"
      ],
      "metadata": {
        "id": "wZvj7DmyqBpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracción de características (Evaluación 1)\n",
        "\n",
        "Aquí solamente almacenaremos los datos necesarios probados por el modelo.\n",
        "\n",
        "\n",
        "\n",
        "Los datos se encuentran **\"resultados1.json\"**.\n",
        "\n",
        "Tiempo de análisis aproximado: **1h 30min**"
      ],
      "metadata": {
        "id": "Sd1-SG4oqD6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from torch import nn\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "rml7BqIxqFEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_imag(url):\n",
        "  response = requests.get(url)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  patch_img = load_image(image.convert(\"RGB\"))\n",
        "  return patch_img, image"
      ],
      "metadata": {
        "id": "4DM61SipqGoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_cap(caption):\n",
        "  cap = \"Does the image describe the following sentence?  \" + caption\n",
        "  text = ofa_tokenizer([cap], return_tensors=\"pt\").to(device).input_ids\n",
        "  return text"
      ],
      "metadata": {
        "id": "SCGbp58ZqHfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_model(caption, patch_img):\n",
        "  gen_output_0 = ofa_model.generate(caption, patch_images=patch_img,num_beams=1, no_repeat_ngram_size=1,  return_dict_in_generate=True , output_scores=True )\n",
        "  ofa_caption_0 = ofa_tokenizer.batch_decode(gen_output_0[0], skip_special_tokens=True)[0].strip()\n",
        "  return ofa_caption_0, gen_output_0"
      ],
      "metadata": {
        "id": "7HnP-CAjqIQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"filtrado.json\", \"r\") as f:\n",
        "    datos = json.load(f)"
      ],
      "metadata": {
        "id": "GOk65aSnqJFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probabilidades(gen_output_0):\n",
        "  probabilities = nn.functional.softmax(gen_output_0[1][0], dim=-1)  # asegurar YES/NO\n",
        "  probYES = probabilities[0][tokens.get(\"yes\")].item()\n",
        "  probNO = probabilities[0][tokens.get(\"no\")].item()\n",
        "  return probYES, probNO"
      ],
      "metadata": {
        "id": "tRt96aQuqKCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = {}\n",
        "tokens = ofa_tokenizer.get_vocab()\n",
        "\n",
        "cont = 0\n",
        "\n",
        "for indice, (clave,valor) in tqdm(enumerate(datos.items())):\n",
        "  probYESP = 0.0\n",
        "  probNOP = 0.0\n",
        "  probYESN = 0.0\n",
        "  probNON = 0.0\n",
        "  respP = \"\"\n",
        "  respN = \"\"\n",
        "\n",
        "  url = valor[\"image_link\"]\n",
        "  patch_img = token_imag(url)[0]\n",
        "  patch_img = patch_img.to(torch.bfloat16)\n",
        "\n",
        "  caption = token_cap(valor[\"caption+\"])\n",
        "  ofa_caption_0, gen_output_0 = input_model(caption, patch_img)\n",
        "  respP = ofa_caption_0\n",
        "\n",
        "  probYESP, probNOP = get_probabilidades(gen_output_0)\n",
        "\n",
        "  caption = token_cap(valor[\"caption-\"])\n",
        "  ofa_caption_0, gen_output_0 = input_model(caption, patch_img)\n",
        "  respN = ofa_caption_0\n",
        "  probYESN, probNON = get_probabilidades(gen_output_0)\n",
        "\n",
        "  valor[\"PY+\"] = probYESP\n",
        "  valor[\"PN+\"] = probNOP\n",
        "  valor[\"response+\"] = respP\n",
        "  valor[\"PY-\"] = probYESN\n",
        "  valor[\"PN-\"] = probNON\n",
        "  valor[\"response-\"] = respN\n",
        "  resultados[cont] = valor\n",
        "  # print(resultados[cont])\n",
        "  cont += 1\n",
        "  # if cont > 500:\n",
        "  #   break\n",
        "\n",
        "with open(\"resultados_large.json\", \"w\") as archivo:\n",
        "  json.dump(resultados, archivo)"
      ],
      "metadata": {
        "id": "JhEIZxlFqLCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"resultados_large.json\", \"w\") as archivo:\n",
        "  json.dump(resultados, archivo)"
      ],
      "metadata": {
        "id": "XHfEwjIvqMCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracción de características (Evaluación 2)\n",
        "\n",
        "Los datos se encuentran **\"resultados_captioner1.json\"**.\n",
        "\n",
        "Tiempo de análisis aproximado: **2h 30min**"
      ],
      "metadata": {
        "id": "_zwxKvUDqN5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from torch import nn\n",
        "import math\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "h19iq5adqPox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_imag(url):\n",
        "  response = requests.get(url)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  patch_img = load_image(image.convert(\"RGB\"))\n",
        "  return patch_img, image"
      ],
      "metadata": {
        "id": "q2Ju6iflqRIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_cap(caption):\n",
        "  text = ofa_tokenizer([caption], padding=True, truncation=True, return_tensors=\"pt\").to(device).input_ids\n",
        "  return text"
      ],
      "metadata": {
        "id": "3Fu3iDR-qSFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"filtrado.json\", \"r\") as f:\n",
        "    datos = json.load(f)"
      ],
      "metadata": {
        "id": "c5Oqa3H4qSwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def probability_to_logit(p):\n",
        "    p = p\n",
        "    if p == 0.0:\n",
        "        return -10000\n",
        "    return np.log(p)"
      ],
      "metadata": {
        "id": "pz2rrOTRqTl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def pro_logs(logits_output, caption=None, caption_ids=None):\n",
        "  sum_pro = 0\n",
        "  mul_pro = 0\n",
        "  suma_log1 = 0\n",
        "  suma_log2 = 0\n",
        "  probabilities = nn.functional.softmax(logits_output.logits, dim=-1)\n",
        "  for i in range(0, len(caption_ids[0]) - 1):\n",
        "    current_id = input\n",
        "    log_1 = logits_output.logits[0][i][caption_ids[0][i+1]].item()\n",
        "    prob = probabilities[0][i][caption_ids[0][i+1]].item()\n",
        "    log_2 = probability_to_logit(prob)\n",
        "    suma_log1 += log_1\n",
        "    sum_pro += prob\n",
        "    mul_pro *= prob\n",
        "    suma_log2 += log_2\n",
        "  return  sum_pro, mul_pro ,suma_log1 ,suma_log2"
      ],
      "metadata": {
        "id": "U9ppW4ZJqVdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_captioner = {}\n",
        "\n",
        "txt = \"what does the image describe?\"\n",
        "inputs = token_cap(txt)\n",
        "tokens = ofa_tokenizer.get_vocab()\n",
        "cont = 0\n",
        "\n",
        "for indice, (clave,valor) in tqdm(enumerate(datos.items())):\n",
        "  url = valor[\"image_link\"]\n",
        "  patch_img = token_imag(url)[0]\n",
        "  patch_img = patch_img.to(torch.bfloat16)\n",
        "  decoder_input_P = token_cap(valor[\"caption+\"])\n",
        "  logits_output_P = ofa_model.forward(input_ids=inputs,patch_images=patch_img, decoder_input_ids=decoder_input_P)\n",
        "  sum_pro_P, mul_pro_P ,suma_log1_P ,suma_log2_P = pro_logs(logits_output_P, caption_ids=decoder_input_P)\n",
        "  valor[\"mul_prob+\"] = mul_pro_P\n",
        "  valor[\"suma_log1+\"] = suma_log1_P\n",
        "  valor[\"suma_log2+\"] = suma_log2_P\n",
        "  valor[\"prob_media+\"] = sum_pro_P/len(partes(valor[\"caption+\"]))\n",
        "\n",
        "  decoder_input_N = token_cap(valor[\"caption-\"])\n",
        "  logits_output_N = ofa_model.forward(input_ids=inputs,patch_images=patch_img, decoder_input_ids=decoder_input_N)\n",
        "  sum_pro_N, mul_pro_N ,suma_log1_N ,suma_log2_N = pro_logs(logits_output_N, caption_ids=decoder_input_N)\n",
        "  valor[\"mul_prob-\"] = mul_pro_N\n",
        "  valor[\"suma_log1-\"] = suma_log1_N\n",
        "  valor[\"suma_log2-\"] = suma_log2_N\n",
        "  valor[\"prob_media-\"] = sum_pro_N/len(partes(valor[\"caption-\"]))\n",
        "\n",
        "  resultados_captioner[cont] = valor\n",
        "  cont += 1\n",
        "\n",
        "with open(\"resultados_captioner_Large_17.json\", \"w\") as archivo:\n",
        "  json.dump(resultados_captioner, archivo)"
      ],
      "metadata": {
        "id": "zdroNbudqXcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"resultados_captioner_Large_17.json\", \"w\") as archivo:\n",
        "  json.dump(resultados_captioner, archivo)"
      ],
      "metadata": {
        "id": "i-HX4oA7qYaN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}